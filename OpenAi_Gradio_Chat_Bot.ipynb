{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "25c5a6c3",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAzzi/ChatBot/blob/main/OpenAi_Gradio_Chat_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272996653310673477252411125948039410165",
      "metadata": {
        "id": "272996653310673477252411125948039410165"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio\n",
        "!pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "288918539441861185822528903084949547379",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "288918539441861185822528903084949547379",
        "outputId": "f33fb513-83bc-43c1-881c-89a043079a18"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "llm = OpenAI(\n",
        "    openai_api_key=\"Your API Key\")\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    def respond(message, chat_history):\n",
        "        bot_message = llm_chain.run(message)\n",
        "        chat_history.append((message, bot_message))\n",
        "        time.sleep(2)\n",
        "        return \"\", chat_history\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
